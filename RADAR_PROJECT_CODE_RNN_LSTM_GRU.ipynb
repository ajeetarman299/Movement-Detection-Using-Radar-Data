{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import uniform, randint\n"
      ],
      "metadata": {
        "id": "R-QVWbMLsQME"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PRE-PROCESSING"
      ],
      "metadata": {
        "id": "2ymh1JDBEf4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/processed_files_separated (2).zip'  # Adjust this path as needed\n",
        "\n",
        "extract_dir = '/content/processed_files_separated(2)'\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n"
      ],
      "metadata": {
        "id": "QZ05ZDNQr6fv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the paths to the directories containing the radar data\n",
        "class_dirs = {\n",
        "    'no_human': '/content/processed_files_separated(2)/processed_files_separated/N',\n",
        "    'human_approaching': '/content/processed_files_separated(2)/processed_files_separated/T',\n",
        "    'human_going_away': '/content/processed_files_separated(2)/processed_files_separated/A'\n",
        "}\n"
      ],
      "metadata": {
        "id": "l5su0jbMsQO5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "chunk_size = 350\n",
        "\n",
        "def process_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = []\n",
        "        for line in file:\n",
        "            try:\n",
        "                data.append(float(line.strip()))\n",
        "            except ValueError:\n",
        "                continue\n",
        "        data = np.array(data)\n",
        "\n",
        "    # Truncate or pad the data to have exactly chunk_size elements\n",
        "    if len(data) > chunk_size:\n",
        "        data = data[-chunk_size:]\n",
        "    elif len(data) < chunk_size:\n",
        "        pad_size = chunk_size - len(data)\n",
        "        data = np.concatenate([data, np.full(pad_size, data.mean())])\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "Y0ygnYl-sQRW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_label = {class_name: i for i, class_name in enumerate(class_dirs.keys())}"
      ],
      "metadata": {
        "id": "muDwa8OUsQUS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "for class_name, dir_path in class_dirs.items():\n",
        "    label = class_to_label[class_name]\n",
        "    for file_name in os.listdir(dir_path):\n",
        "        file_path = os.path.join(dir_path, file_name)\n",
        "        processed_data = process_data(file_path)\n",
        "        data.append(processed_data)\n",
        "        labels.append(label)\n",
        "\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Normalize the data\n",
        "data = (data - data.mean()) / data.std()\n"
      ],
      "metadata": {
        "id": "OV76yOvHsQWv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split data into training, validation, and test sets\n",
        "train_data, temp_data, train_labels, temp_labels = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "val_data, test_data, val_labels, test_labels = train_test_split(temp_data, temp_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "eXPkkKNcsQZV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset class\n",
        "class RadarDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n"
      ],
      "metadata": {
        "id": "E5Kjv8ldshEj"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create dataset and dataloaders\n",
        "train_dataset = RadarDataset(train_data, train_labels)\n",
        "val_dataset = RadarDataset(val_data, val_labels)\n",
        "test_dataset = RadarDataset(test_data, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "upJG9CjQsptq"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_G05Rn24EnI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DL MODELS"
      ],
      "metadata": {
        "id": "VymrudLGEqxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "######-----3\n",
        "# Define the LSTM model with dropout and increased complexity\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_size = 1, hidden_size = 128, num_layers = 3, num_classes = 3, dropout_prob=0.5):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size*2, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        #self.fc3 = nn.Linear(64, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x.unsqueeze(-1), (h0, c0))  # Adding a feature dimension\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        #out = torch.relu(self.fc2(out))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 1  # Since we only have one feature per time step\n",
        "hidden_size = 128  # Increased hidden size\n",
        "num_layers = 3  # Increased number of layers\n",
        "num_classes = 3\n",
        "num_epochs = 100  # Increased number of epochs\n",
        "learning_rate = 0.001\n",
        "dropout_prob = 0.5\n"
      ],
      "metadata": {
        "id": "gIPb6kptspwX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model with dropout and increased complexity\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size = 1, hidden_size = 128, num_layers = 3, num_classes = 3, dropout_prob=0.5):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size*2, 128)\n",
        "       # self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n",
        "\n",
        "        out, _ = self.rnn(x.unsqueeze(-1), h0)  # Adding a feature dimension\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        #out = torch.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "# Hyperparameters\n",
        "input_size = 1  # Since we only have one feature per time step\n",
        "hidden_size = 128  # Increased hidden size\n",
        "num_layers = 3  # Increased number of layers\n",
        "num_classes = 3\n",
        "num_epochs = 100  # Increased number of epochs\n",
        "learning_rate = 0.001\n",
        "dropout_prob = 0.5\n"
      ],
      "metadata": {
        "id": "Bj2f_2n8yVD6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model\n",
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=128, num_layers=3, num_classes=3, dropout_prob=0.5):\n",
        "        super(GRUClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob, bidirectional=True)\n",
        "        self.fc1 = nn.Linear(hidden_size*2, 128)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(x.device)  # *2 for bidirectional\n",
        "        out, _ = self.gru(x.unsqueeze(-1), h0)  # Adding a feature dimension\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        out = torch.relu(self.batch_norm1(self.fc1(out)))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "input_size = 1  # Since we only have one feature per time step\n",
        "hidden_size = 128  # Increased hidden size\n",
        "num_layers = 3  # Increased number of layers\n",
        "num_classes = 3\n",
        "num_epochs = 100  # Increased number of epochs\n",
        "learning_rate = 0.001\n",
        "dropout_prob = 0.5\n"
      ],
      "metadata": {
        "id": "tqB4sgYSyVGy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100, learning_rate=0.001):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    early_stopping_patience = 100\n",
        "    no_improvement_epochs = 0\n",
        "    best_model_path = f'{model.__class__.__name__}_best_model.pth'\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        correct1 = 0\n",
        "        total1 = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, predicted1 = torch.max(outputs.data, 1)\n",
        "            total1 += labels.size(0)\n",
        "            correct1 += (predicted1 == labels).sum().item()\n",
        "            accuracy1 = 100 * correct1 / total1\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            val_loss = 0\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            val_loss /= len(val_loader)\n",
        "            accuracy = 100 * correct / total\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.4f}, Train Accuracy: {accuracy1:.2f}%, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "                no_improvement_epochs = 0\n",
        "            else:\n",
        "                no_improvement_epochs += 1\n",
        "                if no_improvement_epochs >= early_stopping_patience:\n",
        "                    print(\"Early stopping due to no improvement in validation loss\")\n",
        "                    break\n",
        "\n",
        "        scheduler.step(val_loss)  # Adjust the learning rate based on validation loss\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "norwYxskynNI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train RNN, LSTM, and GRU models\n",
        "rnn_model = RNNClassifier()\n",
        "lstm_model = LSTMClassifier()\n",
        "gru_model = GRUClassifier()\n",
        "\n",
        "rnn_model = train_model(rnn_model, train_loader, val_loader)\n",
        "lstm_model = train_model(lstm_model, train_loader, val_loader)\n",
        "gru_model = train_model(gru_model, train_loader, val_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VAqomCU6ynQA",
        "outputId": "8f07b17c-a67d-4ec5-f58c-50942b121d40"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 0.8881, Train Accuracy: 44.63%, Val Loss: 0.9510, Val Accuracy: 52.24%\n",
            "Epoch [2/100], Train Loss: 0.9613, Train Accuracy: 50.75%, Val Loss: 0.9240, Val Accuracy: 55.97%\n",
            "Epoch [3/100], Train Loss: 1.0733, Train Accuracy: 40.60%, Val Loss: 1.0869, Val Accuracy: 26.87%\n",
            "Epoch [4/100], Train Loss: 0.7926, Train Accuracy: 37.01%, Val Loss: 0.9513, Val Accuracy: 55.97%\n",
            "Epoch [5/100], Train Loss: 0.7379, Train Accuracy: 48.51%, Val Loss: 0.9146, Val Accuracy: 57.46%\n",
            "Epoch [6/100], Train Loss: 0.7881, Train Accuracy: 48.81%, Val Loss: 0.9090, Val Accuracy: 55.97%\n",
            "Epoch [7/100], Train Loss: 0.7870, Train Accuracy: 52.54%, Val Loss: 0.8861, Val Accuracy: 55.97%\n",
            "Epoch [8/100], Train Loss: 0.7880, Train Accuracy: 56.42%, Val Loss: 0.8705, Val Accuracy: 60.45%\n",
            "Epoch [9/100], Train Loss: 0.8159, Train Accuracy: 58.96%, Val Loss: 0.8593, Val Accuracy: 61.19%\n",
            "Epoch [10/100], Train Loss: 0.7327, Train Accuracy: 49.55%, Val Loss: 0.9073, Val Accuracy: 47.01%\n",
            "Epoch [11/100], Train Loss: 0.8703, Train Accuracy: 53.43%, Val Loss: 0.9157, Val Accuracy: 57.46%\n",
            "Epoch [12/100], Train Loss: 0.8107, Train Accuracy: 54.18%, Val Loss: 0.8792, Val Accuracy: 58.21%\n",
            "Epoch [13/100], Train Loss: 0.7985, Train Accuracy: 54.03%, Val Loss: 0.8621, Val Accuracy: 58.96%\n",
            "Epoch [14/100], Train Loss: 0.8245, Train Accuracy: 55.82%, Val Loss: 0.8373, Val Accuracy: 60.45%\n",
            "Epoch [15/100], Train Loss: 0.7529, Train Accuracy: 57.46%, Val Loss: 0.8317, Val Accuracy: 60.45%\n",
            "Epoch [16/100], Train Loss: 0.8793, Train Accuracy: 55.67%, Val Loss: 0.9128, Val Accuracy: 52.99%\n",
            "Epoch [17/100], Train Loss: 0.7942, Train Accuracy: 55.52%, Val Loss: 0.8582, Val Accuracy: 60.45%\n",
            "Epoch [18/100], Train Loss: 0.7705, Train Accuracy: 57.91%, Val Loss: 0.8399, Val Accuracy: 60.45%\n",
            "Epoch [19/100], Train Loss: 0.7944, Train Accuracy: 57.16%, Val Loss: 0.8299, Val Accuracy: 61.19%\n",
            "Epoch [20/100], Train Loss: 0.7865, Train Accuracy: 57.46%, Val Loss: 0.8310, Val Accuracy: 61.19%\n",
            "Epoch [21/100], Train Loss: 0.7854, Train Accuracy: 58.21%, Val Loss: 0.8575, Val Accuracy: 60.45%\n",
            "Epoch [22/100], Train Loss: 0.7777, Train Accuracy: 59.10%, Val Loss: 0.8330, Val Accuracy: 60.45%\n",
            "Epoch [23/100], Train Loss: 0.7953, Train Accuracy: 58.66%, Val Loss: 0.8309, Val Accuracy: 61.94%\n",
            "Epoch [24/100], Train Loss: 0.7795, Train Accuracy: 58.96%, Val Loss: 0.8265, Val Accuracy: 61.19%\n",
            "Epoch [25/100], Train Loss: 0.7711, Train Accuracy: 59.70%, Val Loss: 0.8275, Val Accuracy: 61.94%\n",
            "Epoch [26/100], Train Loss: 0.7971, Train Accuracy: 57.76%, Val Loss: 0.8820, Val Accuracy: 59.70%\n",
            "Epoch [27/100], Train Loss: 0.8013, Train Accuracy: 55.97%, Val Loss: 0.8364, Val Accuracy: 60.45%\n",
            "Epoch [28/100], Train Loss: 0.7701, Train Accuracy: 59.85%, Val Loss: 0.8424, Val Accuracy: 61.19%\n",
            "Epoch [29/100], Train Loss: 0.8110, Train Accuracy: 56.87%, Val Loss: 0.8751, Val Accuracy: 59.70%\n",
            "Epoch [30/100], Train Loss: 0.8038, Train Accuracy: 56.87%, Val Loss: 0.8472, Val Accuracy: 60.45%\n",
            "Epoch [31/100], Train Loss: 0.9222, Train Accuracy: 54.63%, Val Loss: 0.9127, Val Accuracy: 59.70%\n",
            "Epoch [32/100], Train Loss: 0.7373, Train Accuracy: 58.36%, Val Loss: 0.8248, Val Accuracy: 60.45%\n",
            "Epoch [33/100], Train Loss: 0.7526, Train Accuracy: 58.06%, Val Loss: 0.8553, Val Accuracy: 59.70%\n",
            "Epoch [34/100], Train Loss: 0.7690, Train Accuracy: 60.15%, Val Loss: 0.8257, Val Accuracy: 62.69%\n",
            "Epoch [35/100], Train Loss: 0.7613, Train Accuracy: 60.90%, Val Loss: 0.7719, Val Accuracy: 64.18%\n",
            "Epoch [36/100], Train Loss: 0.7581, Train Accuracy: 60.30%, Val Loss: 0.8062, Val Accuracy: 63.43%\n",
            "Epoch [37/100], Train Loss: 0.7705, Train Accuracy: 62.09%, Val Loss: 0.7623, Val Accuracy: 64.93%\n",
            "Epoch [38/100], Train Loss: 0.7533, Train Accuracy: 62.09%, Val Loss: 0.7742, Val Accuracy: 64.18%\n",
            "Epoch [39/100], Train Loss: 0.7748, Train Accuracy: 59.55%, Val Loss: 0.8213, Val Accuracy: 64.18%\n",
            "Epoch [40/100], Train Loss: 0.7775, Train Accuracy: 61.79%, Val Loss: 0.7593, Val Accuracy: 67.91%\n",
            "Epoch [41/100], Train Loss: 0.7925, Train Accuracy: 61.04%, Val Loss: 0.7987, Val Accuracy: 64.18%\n",
            "Epoch [42/100], Train Loss: 0.7959, Train Accuracy: 63.28%, Val Loss: 0.7673, Val Accuracy: 66.42%\n",
            "Epoch [43/100], Train Loss: 0.8010, Train Accuracy: 64.03%, Val Loss: 0.7749, Val Accuracy: 66.42%\n",
            "Epoch [44/100], Train Loss: 0.8198, Train Accuracy: 62.69%, Val Loss: 0.7989, Val Accuracy: 65.67%\n",
            "Epoch [45/100], Train Loss: 0.8550, Train Accuracy: 61.64%, Val Loss: 0.8261, Val Accuracy: 65.67%\n",
            "Epoch [46/100], Train Loss: 0.8091, Train Accuracy: 62.09%, Val Loss: 0.7754, Val Accuracy: 64.93%\n",
            "Epoch [47/100], Train Loss: 0.7949, Train Accuracy: 61.94%, Val Loss: 0.8861, Val Accuracy: 56.72%\n",
            "Epoch [48/100], Train Loss: 0.7953, Train Accuracy: 59.55%, Val Loss: 0.8794, Val Accuracy: 61.19%\n",
            "Epoch [49/100], Train Loss: 0.8145, Train Accuracy: 62.69%, Val Loss: 0.8488, Val Accuracy: 63.43%\n",
            "Epoch [50/100], Train Loss: 0.8519, Train Accuracy: 62.54%, Val Loss: 0.8904, Val Accuracy: 57.46%\n",
            "Epoch [51/100], Train Loss: 0.8226, Train Accuracy: 60.75%, Val Loss: 0.8709, Val Accuracy: 61.19%\n",
            "Epoch [52/100], Train Loss: 0.8187, Train Accuracy: 60.30%, Val Loss: 0.8495, Val Accuracy: 62.69%\n",
            "Epoch [53/100], Train Loss: 0.8212, Train Accuracy: 59.70%, Val Loss: 0.8501, Val Accuracy: 63.43%\n",
            "Epoch [54/100], Train Loss: 0.8008, Train Accuracy: 58.51%, Val Loss: 0.8467, Val Accuracy: 56.72%\n",
            "Epoch [55/100], Train Loss: 0.8114, Train Accuracy: 57.61%, Val Loss: 0.8468, Val Accuracy: 53.73%\n",
            "Epoch [56/100], Train Loss: 0.8012, Train Accuracy: 59.25%, Val Loss: 0.8468, Val Accuracy: 56.72%\n",
            "Epoch [57/100], Train Loss: 0.8053, Train Accuracy: 60.90%, Val Loss: 0.8443, Val Accuracy: 62.69%\n",
            "Epoch [58/100], Train Loss: 0.8117, Train Accuracy: 58.66%, Val Loss: 0.8507, Val Accuracy: 62.69%\n",
            "Epoch [59/100], Train Loss: 0.8221, Train Accuracy: 62.09%, Val Loss: 0.8544, Val Accuracy: 61.19%\n",
            "Epoch [60/100], Train Loss: 0.8167, Train Accuracy: 61.34%, Val Loss: 0.8420, Val Accuracy: 62.69%\n",
            "Epoch [61/100], Train Loss: 0.8194, Train Accuracy: 60.15%, Val Loss: 0.8483, Val Accuracy: 62.69%\n",
            "Epoch [62/100], Train Loss: 0.8198, Train Accuracy: 60.90%, Val Loss: 0.8443, Val Accuracy: 62.69%\n",
            "Epoch [63/100], Train Loss: 0.8196, Train Accuracy: 60.30%, Val Loss: 0.8441, Val Accuracy: 62.69%\n",
            "Epoch [64/100], Train Loss: 0.8194, Train Accuracy: 60.15%, Val Loss: 0.8444, Val Accuracy: 62.69%\n",
            "Epoch [65/100], Train Loss: 0.8193, Train Accuracy: 60.30%, Val Loss: 0.8446, Val Accuracy: 62.69%\n",
            "Epoch [66/100], Train Loss: 0.8192, Train Accuracy: 60.30%, Val Loss: 0.8439, Val Accuracy: 62.69%\n",
            "Epoch [67/100], Train Loss: 0.8193, Train Accuracy: 62.54%, Val Loss: 0.8434, Val Accuracy: 62.69%\n",
            "Epoch [68/100], Train Loss: 0.8193, Train Accuracy: 60.90%, Val Loss: 0.8425, Val Accuracy: 62.69%\n",
            "Epoch [69/100], Train Loss: 0.8195, Train Accuracy: 60.75%, Val Loss: 0.8426, Val Accuracy: 62.69%\n",
            "Epoch [70/100], Train Loss: 0.8194, Train Accuracy: 61.19%, Val Loss: 0.8427, Val Accuracy: 62.69%\n",
            "Epoch [71/100], Train Loss: 0.8192, Train Accuracy: 60.30%, Val Loss: 0.8427, Val Accuracy: 62.69%\n",
            "Epoch [72/100], Train Loss: 0.8185, Train Accuracy: 61.04%, Val Loss: 0.8450, Val Accuracy: 62.69%\n",
            "Epoch [73/100], Train Loss: 0.7896, Train Accuracy: 60.45%, Val Loss: 0.8402, Val Accuracy: 62.69%\n",
            "Epoch [74/100], Train Loss: 0.7896, Train Accuracy: 60.00%, Val Loss: 0.8403, Val Accuracy: 62.69%\n",
            "Epoch [75/100], Train Loss: 0.7896, Train Accuracy: 60.75%, Val Loss: 0.8406, Val Accuracy: 62.69%\n",
            "Epoch [76/100], Train Loss: 0.7896, Train Accuracy: 60.60%, Val Loss: 0.8407, Val Accuracy: 62.69%\n",
            "Epoch [77/100], Train Loss: 0.7896, Train Accuracy: 61.04%, Val Loss: 0.8408, Val Accuracy: 62.69%\n",
            "Epoch [78/100], Train Loss: 0.7896, Train Accuracy: 60.15%, Val Loss: 0.8409, Val Accuracy: 62.69%\n",
            "Epoch [79/100], Train Loss: 0.7896, Train Accuracy: 61.04%, Val Loss: 0.8410, Val Accuracy: 62.69%\n",
            "Epoch [80/100], Train Loss: 0.7897, Train Accuracy: 60.30%, Val Loss: 0.8410, Val Accuracy: 62.69%\n",
            "Epoch [81/100], Train Loss: 0.7897, Train Accuracy: 60.15%, Val Loss: 0.8410, Val Accuracy: 62.69%\n",
            "Epoch [82/100], Train Loss: 0.7897, Train Accuracy: 60.90%, Val Loss: 0.8411, Val Accuracy: 62.69%\n",
            "Epoch [83/100], Train Loss: 0.7897, Train Accuracy: 60.00%, Val Loss: 0.8404, Val Accuracy: 62.69%\n",
            "Epoch [84/100], Train Loss: 0.7898, Train Accuracy: 60.75%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [85/100], Train Loss: 0.7898, Train Accuracy: 60.90%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [86/100], Train Loss: 0.7898, Train Accuracy: 60.90%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [87/100], Train Loss: 0.7898, Train Accuracy: 60.90%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [88/100], Train Loss: 0.7898, Train Accuracy: 60.75%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [89/100], Train Loss: 0.7898, Train Accuracy: 61.49%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [90/100], Train Loss: 0.7898, Train Accuracy: 61.64%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [91/100], Train Loss: 0.7898, Train Accuracy: 61.04%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [92/100], Train Loss: 0.7898, Train Accuracy: 60.60%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [93/100], Train Loss: 0.7898, Train Accuracy: 60.30%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [94/100], Train Loss: 0.7898, Train Accuracy: 61.04%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [95/100], Train Loss: 0.7898, Train Accuracy: 60.90%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [96/100], Train Loss: 0.7898, Train Accuracy: 60.30%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [97/100], Train Loss: 0.7898, Train Accuracy: 61.64%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [98/100], Train Loss: 0.7898, Train Accuracy: 60.60%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [99/100], Train Loss: 0.7898, Train Accuracy: 60.15%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [100/100], Train Loss: 0.7898, Train Accuracy: 61.34%, Val Loss: 0.8405, Val Accuracy: 62.69%\n",
            "Epoch [1/100], Train Loss: 1.0429, Train Accuracy: 39.25%, Val Loss: 1.0411, Val Accuracy: 51.49%\n",
            "Epoch [2/100], Train Loss: 0.9080, Train Accuracy: 53.58%, Val Loss: 0.9789, Val Accuracy: 52.99%\n",
            "Epoch [3/100], Train Loss: 0.9426, Train Accuracy: 54.78%, Val Loss: 0.9559, Val Accuracy: 53.73%\n",
            "Epoch [4/100], Train Loss: 1.1362, Train Accuracy: 57.91%, Val Loss: 0.8608, Val Accuracy: 64.18%\n",
            "Epoch [5/100], Train Loss: 0.6668, Train Accuracy: 60.45%, Val Loss: 0.7959, Val Accuracy: 64.93%\n",
            "Epoch [6/100], Train Loss: 0.9535, Train Accuracy: 50.75%, Val Loss: 0.9960, Val Accuracy: 47.76%\n",
            "Epoch [7/100], Train Loss: 1.1741, Train Accuracy: 44.33%, Val Loss: 1.0336, Val Accuracy: 47.01%\n",
            "Epoch [8/100], Train Loss: 0.8481, Train Accuracy: 48.21%, Val Loss: 0.8130, Val Accuracy: 64.93%\n",
            "Epoch [9/100], Train Loss: 0.9817, Train Accuracy: 46.12%, Val Loss: 0.9981, Val Accuracy: 53.73%\n",
            "Epoch [10/100], Train Loss: 0.9673, Train Accuracy: 49.70%, Val Loss: 0.9952, Val Accuracy: 52.99%\n",
            "Epoch [11/100], Train Loss: 0.9405, Train Accuracy: 52.24%, Val Loss: 0.9831, Val Accuracy: 52.99%\n",
            "Epoch [12/100], Train Loss: 0.9481, Train Accuracy: 52.84%, Val Loss: 0.9558, Val Accuracy: 52.99%\n",
            "Epoch [13/100], Train Loss: 0.8520, Train Accuracy: 52.99%, Val Loss: 0.8762, Val Accuracy: 58.96%\n",
            "Epoch [14/100], Train Loss: 0.9795, Train Accuracy: 61.04%, Val Loss: 0.8866, Val Accuracy: 64.93%\n",
            "Epoch [15/100], Train Loss: 0.7048, Train Accuracy: 64.78%, Val Loss: 0.7567, Val Accuracy: 70.15%\n",
            "Epoch [16/100], Train Loss: 0.7982, Train Accuracy: 64.18%, Val Loss: 0.7586, Val Accuracy: 65.67%\n",
            "Epoch [17/100], Train Loss: 0.8097, Train Accuracy: 63.58%, Val Loss: 0.7371, Val Accuracy: 73.88%\n",
            "Epoch [18/100], Train Loss: 0.7314, Train Accuracy: 63.28%, Val Loss: 0.7673, Val Accuracy: 67.91%\n",
            "Epoch [19/100], Train Loss: 0.7405, Train Accuracy: 60.60%, Val Loss: 0.8070, Val Accuracy: 59.70%\n",
            "Epoch [20/100], Train Loss: 0.6676, Train Accuracy: 60.00%, Val Loss: 0.7237, Val Accuracy: 73.88%\n",
            "Epoch [21/100], Train Loss: 0.7578, Train Accuracy: 69.85%, Val Loss: 0.6811, Val Accuracy: 75.37%\n",
            "Epoch [22/100], Train Loss: 0.4308, Train Accuracy: 68.81%, Val Loss: 0.7038, Val Accuracy: 71.64%\n",
            "Epoch [23/100], Train Loss: 0.5209, Train Accuracy: 68.96%, Val Loss: 0.7062, Val Accuracy: 71.64%\n",
            "Epoch [24/100], Train Loss: 0.6551, Train Accuracy: 67.01%, Val Loss: 0.7158, Val Accuracy: 72.39%\n",
            "Epoch [25/100], Train Loss: 1.0386, Train Accuracy: 51.49%, Val Loss: 1.0034, Val Accuracy: 52.24%\n",
            "Epoch [26/100], Train Loss: 0.9156, Train Accuracy: 52.69%, Val Loss: 0.9506, Val Accuracy: 55.97%\n",
            "Epoch [27/100], Train Loss: 0.8877, Train Accuracy: 54.78%, Val Loss: 0.8870, Val Accuracy: 64.18%\n",
            "Epoch [28/100], Train Loss: 0.9216, Train Accuracy: 57.91%, Val Loss: 0.8382, Val Accuracy: 67.91%\n",
            "Epoch [29/100], Train Loss: 0.8027, Train Accuracy: 60.30%, Val Loss: 0.8213, Val Accuracy: 64.18%\n",
            "Epoch [30/100], Train Loss: 0.7395, Train Accuracy: 61.04%, Val Loss: 0.8101, Val Accuracy: 64.18%\n",
            "Epoch [31/100], Train Loss: 0.6498, Train Accuracy: 61.64%, Val Loss: 0.7618, Val Accuracy: 66.42%\n",
            "Epoch [32/100], Train Loss: 0.6985, Train Accuracy: 60.15%, Val Loss: 0.8147, Val Accuracy: 67.91%\n",
            "Epoch [33/100], Train Loss: 0.7343, Train Accuracy: 61.94%, Val Loss: 0.8108, Val Accuracy: 64.93%\n",
            "Epoch [34/100], Train Loss: 0.7490, Train Accuracy: 62.99%, Val Loss: 0.8109, Val Accuracy: 64.93%\n",
            "Epoch [35/100], Train Loss: 0.7169, Train Accuracy: 61.79%, Val Loss: 0.7942, Val Accuracy: 64.18%\n",
            "Epoch [36/100], Train Loss: 0.7114, Train Accuracy: 62.69%, Val Loss: 0.7935, Val Accuracy: 64.18%\n",
            "Epoch [37/100], Train Loss: 0.7042, Train Accuracy: 62.09%, Val Loss: 0.7888, Val Accuracy: 64.18%\n",
            "Epoch [38/100], Train Loss: 0.6923, Train Accuracy: 62.09%, Val Loss: 0.7850, Val Accuracy: 64.18%\n",
            "Epoch [39/100], Train Loss: 0.6959, Train Accuracy: 62.84%, Val Loss: 0.7833, Val Accuracy: 64.93%\n",
            "Epoch [40/100], Train Loss: 0.6946, Train Accuracy: 63.28%, Val Loss: 0.7768, Val Accuracy: 65.67%\n",
            "Epoch [41/100], Train Loss: 0.7025, Train Accuracy: 63.13%, Val Loss: 0.7785, Val Accuracy: 66.42%\n",
            "Epoch [42/100], Train Loss: 0.6949, Train Accuracy: 62.09%, Val Loss: 0.7722, Val Accuracy: 64.93%\n",
            "Epoch [43/100], Train Loss: 0.6970, Train Accuracy: 64.03%, Val Loss: 0.7724, Val Accuracy: 65.67%\n",
            "Epoch [44/100], Train Loss: 0.6969, Train Accuracy: 63.43%, Val Loss: 0.7719, Val Accuracy: 65.67%\n",
            "Epoch [45/100], Train Loss: 0.6960, Train Accuracy: 64.63%, Val Loss: 0.7711, Val Accuracy: 65.67%\n",
            "Epoch [46/100], Train Loss: 0.6966, Train Accuracy: 62.99%, Val Loss: 0.7714, Val Accuracy: 66.42%\n",
            "Epoch [47/100], Train Loss: 0.6950, Train Accuracy: 62.99%, Val Loss: 0.7703, Val Accuracy: 66.42%\n",
            "Epoch [48/100], Train Loss: 0.6939, Train Accuracy: 62.99%, Val Loss: 0.7695, Val Accuracy: 65.67%\n",
            "Epoch [49/100], Train Loss: 0.6937, Train Accuracy: 64.63%, Val Loss: 0.7692, Val Accuracy: 65.67%\n",
            "Epoch [50/100], Train Loss: 0.6930, Train Accuracy: 62.99%, Val Loss: 0.7688, Val Accuracy: 65.67%\n",
            "Epoch [51/100], Train Loss: 0.6934, Train Accuracy: 63.88%, Val Loss: 0.7687, Val Accuracy: 66.42%\n",
            "Epoch [52/100], Train Loss: 0.6937, Train Accuracy: 63.58%, Val Loss: 0.7686, Val Accuracy: 66.42%\n",
            "Epoch [53/100], Train Loss: 0.6929, Train Accuracy: 64.48%, Val Loss: 0.7683, Val Accuracy: 66.42%\n",
            "Epoch [54/100], Train Loss: 0.6930, Train Accuracy: 63.73%, Val Loss: 0.7680, Val Accuracy: 66.42%\n",
            "Epoch [55/100], Train Loss: 0.6930, Train Accuracy: 63.58%, Val Loss: 0.7680, Val Accuracy: 66.42%\n",
            "Epoch [56/100], Train Loss: 0.6930, Train Accuracy: 63.58%, Val Loss: 0.7680, Val Accuracy: 66.42%\n",
            "Epoch [57/100], Train Loss: 0.6931, Train Accuracy: 62.99%, Val Loss: 0.7680, Val Accuracy: 66.42%\n",
            "Epoch [58/100], Train Loss: 0.6929, Train Accuracy: 63.58%, Val Loss: 0.7679, Val Accuracy: 66.42%\n",
            "Epoch [59/100], Train Loss: 0.6930, Train Accuracy: 64.63%, Val Loss: 0.7679, Val Accuracy: 66.42%\n",
            "Epoch [60/100], Train Loss: 0.6930, Train Accuracy: 64.33%, Val Loss: 0.7679, Val Accuracy: 66.42%\n",
            "Epoch [61/100], Train Loss: 0.6930, Train Accuracy: 64.03%, Val Loss: 0.7679, Val Accuracy: 66.42%\n",
            "Epoch [62/100], Train Loss: 0.6930, Train Accuracy: 63.28%, Val Loss: 0.7679, Val Accuracy: 66.42%\n",
            "Epoch [63/100], Train Loss: 0.6930, Train Accuracy: 63.73%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [64/100], Train Loss: 0.6930, Train Accuracy: 62.99%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [65/100], Train Loss: 0.6931, Train Accuracy: 64.03%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [66/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [67/100], Train Loss: 0.6931, Train Accuracy: 64.33%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [68/100], Train Loss: 0.6931, Train Accuracy: 64.33%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [69/100], Train Loss: 0.6931, Train Accuracy: 64.48%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [70/100], Train Loss: 0.6931, Train Accuracy: 62.84%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [71/100], Train Loss: 0.6931, Train Accuracy: 64.63%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [72/100], Train Loss: 0.6931, Train Accuracy: 63.58%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [73/100], Train Loss: 0.6931, Train Accuracy: 63.43%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [74/100], Train Loss: 0.6931, Train Accuracy: 64.18%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [75/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [76/100], Train Loss: 0.6931, Train Accuracy: 62.39%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [77/100], Train Loss: 0.6931, Train Accuracy: 63.73%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [78/100], Train Loss: 0.6931, Train Accuracy: 63.43%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [79/100], Train Loss: 0.6931, Train Accuracy: 64.78%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [80/100], Train Loss: 0.6931, Train Accuracy: 63.43%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [81/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [82/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [83/100], Train Loss: 0.6931, Train Accuracy: 63.28%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [84/100], Train Loss: 0.6931, Train Accuracy: 62.99%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [85/100], Train Loss: 0.6931, Train Accuracy: 63.43%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [86/100], Train Loss: 0.6931, Train Accuracy: 64.48%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [87/100], Train Loss: 0.6931, Train Accuracy: 63.58%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [88/100], Train Loss: 0.6931, Train Accuracy: 64.63%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [89/100], Train Loss: 0.6931, Train Accuracy: 63.73%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [90/100], Train Loss: 0.6931, Train Accuracy: 62.84%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [91/100], Train Loss: 0.6931, Train Accuracy: 63.73%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [92/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [93/100], Train Loss: 0.6931, Train Accuracy: 64.63%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [94/100], Train Loss: 0.6931, Train Accuracy: 64.03%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [95/100], Train Loss: 0.6931, Train Accuracy: 64.03%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [96/100], Train Loss: 0.6931, Train Accuracy: 64.48%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [97/100], Train Loss: 0.6931, Train Accuracy: 63.73%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [98/100], Train Loss: 0.6931, Train Accuracy: 62.39%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [99/100], Train Loss: 0.6931, Train Accuracy: 63.88%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [100/100], Train Loss: 0.6931, Train Accuracy: 62.39%, Val Loss: 0.7678, Val Accuracy: 66.42%\n",
            "Epoch [1/100], Train Loss: 1.0230, Train Accuracy: 40.30%, Val Loss: 1.0646, Val Accuracy: 29.85%\n",
            "Epoch [2/100], Train Loss: 0.9287, Train Accuracy: 40.75%, Val Loss: 0.9785, Val Accuracy: 53.73%\n",
            "Epoch [3/100], Train Loss: 0.9421, Train Accuracy: 51.79%, Val Loss: 0.9574, Val Accuracy: 52.24%\n",
            "Epoch [4/100], Train Loss: 0.9013, Train Accuracy: 54.93%, Val Loss: 0.8736, Val Accuracy: 58.21%\n",
            "Epoch [5/100], Train Loss: 1.1451, Train Accuracy: 59.40%, Val Loss: 0.8712, Val Accuracy: 64.93%\n",
            "Epoch [6/100], Train Loss: 1.1888, Train Accuracy: 57.46%, Val Loss: 0.9116, Val Accuracy: 64.18%\n",
            "Epoch [7/100], Train Loss: 0.9151, Train Accuracy: 63.43%, Val Loss: 0.7697, Val Accuracy: 66.42%\n",
            "Epoch [8/100], Train Loss: 0.7990, Train Accuracy: 65.97%, Val Loss: 0.7214, Val Accuracy: 74.63%\n",
            "Epoch [9/100], Train Loss: 0.6170, Train Accuracy: 67.31%, Val Loss: 0.7209, Val Accuracy: 71.64%\n",
            "Epoch [10/100], Train Loss: 0.5746, Train Accuracy: 71.94%, Val Loss: 0.6035, Val Accuracy: 78.36%\n",
            "Epoch [11/100], Train Loss: 0.5034, Train Accuracy: 74.93%, Val Loss: 0.5194, Val Accuracy: 81.34%\n",
            "Epoch [12/100], Train Loss: 0.3143, Train Accuracy: 77.31%, Val Loss: 0.4964, Val Accuracy: 82.09%\n",
            "Epoch [13/100], Train Loss: 0.5019, Train Accuracy: 78.96%, Val Loss: 0.5423, Val Accuracy: 81.34%\n",
            "Epoch [14/100], Train Loss: 0.7303, Train Accuracy: 80.30%, Val Loss: 0.7286, Val Accuracy: 61.19%\n",
            "Epoch [15/100], Train Loss: 0.7662, Train Accuracy: 80.90%, Val Loss: 0.5617, Val Accuracy: 83.58%\n",
            "Epoch [16/100], Train Loss: 0.5740, Train Accuracy: 81.19%, Val Loss: 0.5462, Val Accuracy: 82.09%\n",
            "Epoch [17/100], Train Loss: 0.3915, Train Accuracy: 82.24%, Val Loss: 0.4740, Val Accuracy: 83.58%\n",
            "Epoch [18/100], Train Loss: 0.4185, Train Accuracy: 82.99%, Val Loss: 0.4671, Val Accuracy: 85.07%\n",
            "Epoch [19/100], Train Loss: 0.4332, Train Accuracy: 82.69%, Val Loss: 0.4837, Val Accuracy: 82.84%\n",
            "Epoch [20/100], Train Loss: 0.4981, Train Accuracy: 82.69%, Val Loss: 0.5011, Val Accuracy: 82.84%\n",
            "Epoch [21/100], Train Loss: 0.6274, Train Accuracy: 83.43%, Val Loss: 0.5250, Val Accuracy: 81.34%\n",
            "Epoch [22/100], Train Loss: 0.8851, Train Accuracy: 84.63%, Val Loss: 0.5714, Val Accuracy: 82.09%\n",
            "Epoch [23/100], Train Loss: 0.4927, Train Accuracy: 84.93%, Val Loss: 0.4881, Val Accuracy: 82.84%\n",
            "Epoch [24/100], Train Loss: 0.4073, Train Accuracy: 84.48%, Val Loss: 0.4375, Val Accuracy: 84.33%\n",
            "Epoch [25/100], Train Loss: 1.3928, Train Accuracy: 85.22%, Val Loss: 0.6829, Val Accuracy: 82.09%\n",
            "Epoch [26/100], Train Loss: 0.6664, Train Accuracy: 83.88%, Val Loss: 0.5391, Val Accuracy: 82.09%\n",
            "Epoch [27/100], Train Loss: 0.1596, Train Accuracy: 85.52%, Val Loss: 0.4012, Val Accuracy: 84.33%\n",
            "Epoch [28/100], Train Loss: 0.5644, Train Accuracy: 83.13%, Val Loss: 0.4684, Val Accuracy: 83.58%\n",
            "Epoch [29/100], Train Loss: 0.2153, Train Accuracy: 85.37%, Val Loss: 0.3963, Val Accuracy: 83.58%\n",
            "Epoch [30/100], Train Loss: 0.6874, Train Accuracy: 86.72%, Val Loss: 0.5182, Val Accuracy: 82.84%\n",
            "Epoch [31/100], Train Loss: 0.2496, Train Accuracy: 86.42%, Val Loss: 0.4020, Val Accuracy: 83.58%\n",
            "Epoch [32/100], Train Loss: 0.4477, Train Accuracy: 87.31%, Val Loss: 0.4511, Val Accuracy: 84.33%\n",
            "Epoch [33/100], Train Loss: 0.2630, Train Accuracy: 87.61%, Val Loss: 0.4532, Val Accuracy: 83.58%\n",
            "Epoch [34/100], Train Loss: 0.7607, Train Accuracy: 87.01%, Val Loss: 0.6176, Val Accuracy: 80.60%\n",
            "Epoch [35/100], Train Loss: 0.3358, Train Accuracy: 88.96%, Val Loss: 0.4320, Val Accuracy: 86.57%\n",
            "Epoch [36/100], Train Loss: 0.2423, Train Accuracy: 89.10%, Val Loss: 0.4004, Val Accuracy: 83.58%\n",
            "Epoch [37/100], Train Loss: 0.4612, Train Accuracy: 89.25%, Val Loss: 0.5082, Val Accuracy: 82.84%\n",
            "Epoch [38/100], Train Loss: 0.1230, Train Accuracy: 88.96%, Val Loss: 0.4537, Val Accuracy: 82.09%\n",
            "Epoch [39/100], Train Loss: 0.2162, Train Accuracy: 90.30%, Val Loss: 0.4300, Val Accuracy: 82.84%\n",
            "Epoch [40/100], Train Loss: 0.1801, Train Accuracy: 87.16%, Val Loss: 0.3832, Val Accuracy: 84.33%\n",
            "Epoch [41/100], Train Loss: 0.5992, Train Accuracy: 89.70%, Val Loss: 0.4865, Val Accuracy: 81.34%\n",
            "Epoch [42/100], Train Loss: 0.1090, Train Accuracy: 90.60%, Val Loss: 0.4213, Val Accuracy: 81.34%\n",
            "Epoch [43/100], Train Loss: 0.1676, Train Accuracy: 92.54%, Val Loss: 0.3902, Val Accuracy: 80.60%\n",
            "Epoch [44/100], Train Loss: 0.1064, Train Accuracy: 93.73%, Val Loss: 0.3917, Val Accuracy: 84.33%\n",
            "Epoch [45/100], Train Loss: 0.1548, Train Accuracy: 93.43%, Val Loss: 0.4125, Val Accuracy: 82.09%\n",
            "Epoch [46/100], Train Loss: 0.1675, Train Accuracy: 90.90%, Val Loss: 0.4673, Val Accuracy: 84.33%\n",
            "Epoch [47/100], Train Loss: 0.2977, Train Accuracy: 91.04%, Val Loss: 0.4497, Val Accuracy: 82.09%\n",
            "Epoch [48/100], Train Loss: 0.0589, Train Accuracy: 92.84%, Val Loss: 0.4350, Val Accuracy: 82.09%\n",
            "Epoch [49/100], Train Loss: 0.0742, Train Accuracy: 94.48%, Val Loss: 0.4084, Val Accuracy: 82.84%\n",
            "Epoch [50/100], Train Loss: 0.3797, Train Accuracy: 93.28%, Val Loss: 0.5299, Val Accuracy: 83.58%\n",
            "Epoch [51/100], Train Loss: 0.0855, Train Accuracy: 93.13%, Val Loss: 0.4798, Val Accuracy: 81.34%\n",
            "Epoch [52/100], Train Loss: 0.0872, Train Accuracy: 94.63%, Val Loss: 0.4190, Val Accuracy: 82.09%\n",
            "Epoch [53/100], Train Loss: 0.0614, Train Accuracy: 96.42%, Val Loss: 0.3975, Val Accuracy: 82.84%\n",
            "Epoch [54/100], Train Loss: 0.0726, Train Accuracy: 97.31%, Val Loss: 0.4047, Val Accuracy: 83.58%\n",
            "Epoch [55/100], Train Loss: 0.1007, Train Accuracy: 97.31%, Val Loss: 0.3998, Val Accuracy: 84.33%\n",
            "Epoch [56/100], Train Loss: 0.1218, Train Accuracy: 97.16%, Val Loss: 0.4080, Val Accuracy: 85.82%\n",
            "Epoch [57/100], Train Loss: 0.0842, Train Accuracy: 97.01%, Val Loss: 0.3899, Val Accuracy: 83.58%\n",
            "Epoch [58/100], Train Loss: 0.0684, Train Accuracy: 97.31%, Val Loss: 0.3761, Val Accuracy: 84.33%\n",
            "Epoch [59/100], Train Loss: 0.0717, Train Accuracy: 97.61%, Val Loss: 0.3803, Val Accuracy: 85.82%\n",
            "Epoch [60/100], Train Loss: 0.0440, Train Accuracy: 97.16%, Val Loss: 0.4154, Val Accuracy: 85.07%\n",
            "Epoch [61/100], Train Loss: 0.0575, Train Accuracy: 97.91%, Val Loss: 0.3909, Val Accuracy: 84.33%\n",
            "Epoch [62/100], Train Loss: 0.0663, Train Accuracy: 97.76%, Val Loss: 0.3792, Val Accuracy: 86.57%\n",
            "Epoch [63/100], Train Loss: 0.0592, Train Accuracy: 97.76%, Val Loss: 0.3805, Val Accuracy: 87.31%\n",
            "Epoch [64/100], Train Loss: 0.0366, Train Accuracy: 97.46%, Val Loss: 0.3691, Val Accuracy: 86.57%\n",
            "Epoch [65/100], Train Loss: 0.0507, Train Accuracy: 97.46%, Val Loss: 0.3860, Val Accuracy: 86.57%\n",
            "Epoch [66/100], Train Loss: 0.0402, Train Accuracy: 97.46%, Val Loss: 0.3625, Val Accuracy: 88.06%\n",
            "Epoch [67/100], Train Loss: 0.0892, Train Accuracy: 97.46%, Val Loss: 0.4085, Val Accuracy: 86.57%\n",
            "Epoch [68/100], Train Loss: 0.0191, Train Accuracy: 97.31%, Val Loss: 0.3939, Val Accuracy: 85.07%\n",
            "Epoch [69/100], Train Loss: 0.0697, Train Accuracy: 98.81%, Val Loss: 0.3871, Val Accuracy: 87.31%\n",
            "Epoch [70/100], Train Loss: 0.0241, Train Accuracy: 98.51%, Val Loss: 0.3727, Val Accuracy: 86.57%\n",
            "Epoch [71/100], Train Loss: 0.0150, Train Accuracy: 97.76%, Val Loss: 0.3574, Val Accuracy: 87.31%\n",
            "Epoch [72/100], Train Loss: 0.0325, Train Accuracy: 98.51%, Val Loss: 0.3472, Val Accuracy: 88.06%\n",
            "Epoch [73/100], Train Loss: 0.0451, Train Accuracy: 98.36%, Val Loss: 0.3510, Val Accuracy: 88.06%\n",
            "Epoch [74/100], Train Loss: 0.0584, Train Accuracy: 98.96%, Val Loss: 0.3723, Val Accuracy: 88.81%\n",
            "Epoch [75/100], Train Loss: 0.0097, Train Accuracy: 97.91%, Val Loss: 0.3654, Val Accuracy: 88.81%\n",
            "Epoch [76/100], Train Loss: 0.0480, Train Accuracy: 98.81%, Val Loss: 0.4007, Val Accuracy: 88.06%\n",
            "Epoch [77/100], Train Loss: 0.0244, Train Accuracy: 97.91%, Val Loss: 0.3658, Val Accuracy: 88.81%\n",
            "Epoch [78/100], Train Loss: 0.0360, Train Accuracy: 98.36%, Val Loss: 0.3650, Val Accuracy: 88.81%\n",
            "Epoch [79/100], Train Loss: 0.0557, Train Accuracy: 98.36%, Val Loss: 0.3988, Val Accuracy: 87.31%\n",
            "Epoch [80/100], Train Loss: 0.0107, Train Accuracy: 98.06%, Val Loss: 0.3488, Val Accuracy: 88.06%\n",
            "Epoch [81/100], Train Loss: 0.0177, Train Accuracy: 98.06%, Val Loss: 0.3510, Val Accuracy: 89.55%\n",
            "Epoch [82/100], Train Loss: 0.0158, Train Accuracy: 98.06%, Val Loss: 0.3724, Val Accuracy: 87.31%\n",
            "Epoch [83/100], Train Loss: 0.0095, Train Accuracy: 97.91%, Val Loss: 0.3784, Val Accuracy: 87.31%\n",
            "Epoch [84/100], Train Loss: 0.0123, Train Accuracy: 99.10%, Val Loss: 0.3702, Val Accuracy: 87.31%\n",
            "Epoch [85/100], Train Loss: 0.0141, Train Accuracy: 97.91%, Val Loss: 0.3872, Val Accuracy: 88.06%\n",
            "Epoch [86/100], Train Loss: 0.0173, Train Accuracy: 99.10%, Val Loss: 0.3728, Val Accuracy: 88.06%\n",
            "Epoch [87/100], Train Loss: 0.0206, Train Accuracy: 98.36%, Val Loss: 0.3872, Val Accuracy: 88.06%\n",
            "Epoch [88/100], Train Loss: 0.0157, Train Accuracy: 98.81%, Val Loss: 0.3725, Val Accuracy: 88.06%\n",
            "Epoch [89/100], Train Loss: 0.0146, Train Accuracy: 98.96%, Val Loss: 0.3694, Val Accuracy: 88.06%\n",
            "Epoch [90/100], Train Loss: 0.0098, Train Accuracy: 98.36%, Val Loss: 0.3537, Val Accuracy: 88.06%\n",
            "Epoch [91/100], Train Loss: 0.0110, Train Accuracy: 98.51%, Val Loss: 0.3552, Val Accuracy: 87.31%\n",
            "Epoch [92/100], Train Loss: 0.0144, Train Accuracy: 98.51%, Val Loss: 0.3706, Val Accuracy: 88.06%\n",
            "Epoch [93/100], Train Loss: 0.0246, Train Accuracy: 98.51%, Val Loss: 0.3851, Val Accuracy: 88.06%\n",
            "Epoch [94/100], Train Loss: 0.0276, Train Accuracy: 99.10%, Val Loss: 0.3867, Val Accuracy: 88.06%\n",
            "Epoch [95/100], Train Loss: 0.0227, Train Accuracy: 98.81%, Val Loss: 0.3729, Val Accuracy: 88.06%\n",
            "Epoch [96/100], Train Loss: 0.0241, Train Accuracy: 98.51%, Val Loss: 0.3711, Val Accuracy: 88.06%\n",
            "Epoch [97/100], Train Loss: 0.0243, Train Accuracy: 99.10%, Val Loss: 0.3799, Val Accuracy: 88.06%\n",
            "Epoch [98/100], Train Loss: 0.0256, Train Accuracy: 98.96%, Val Loss: 0.3816, Val Accuracy: 88.06%\n",
            "Epoch [99/100], Train Loss: 0.0207, Train Accuracy: 98.36%, Val Loss: 0.3725, Val Accuracy: 88.06%\n",
            "Epoch [100/100], Train Loss: 0.0205, Train Accuracy: 98.21%, Val Loss: 0.3790, Val Accuracy: 88.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensemble prediction\n",
        "def ensemble_predict(models, test_loader):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    all_outputs = []\n",
        "    for model in models:\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        outputs = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, _ in test_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                output = model(inputs)\n",
        "                outputs.append(output.cpu().numpy())\n",
        "        all_outputs.append(np.concatenate(outputs))\n",
        "\n",
        "    # Average the outputs\n",
        "    averaged_outputs = np.mean(all_outputs, axis=0)\n",
        "    ensemble_predictions = np.argmax(averaged_outputs, axis=1)\n",
        "    return ensemble_predictions\n"
      ],
      "metadata": {
        "id": "FMhpK8uyynSh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate ensemble model\n",
        "models = [rnn_model, lstm_model, gru_model]\n",
        "ensemble_predictions = ensemble_predict(models, test_loader)\n",
        "ensemble_accuracy = accuracy_score(test_labels, ensemble_predictions)\n",
        "print(f'Ensemble Test Accuracy: {ensemble_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OvKa4cnynVP",
        "outputId": "c363c576-5394-482c-a61c-c55efdbfdc24"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Test Accuracy: 0.85%\n"
          ]
        }
      ]
    }
  ]
}